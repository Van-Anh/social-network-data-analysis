{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       friend_id       name\n",
      "0            341      41188\n",
      "1            535      41188\n",
      "2           5408      41188\n",
      "3           5948      41188\n",
      "4           6998      41188\n",
      "...          ...        ...\n",
      "27519  565647440  254427002\n",
      "27520  589493869  254427002\n",
      "27521  594573653  254427002\n",
      "27522  597831849  254427002\n",
      "27523  609007855  254427002\n",
      "\n",
      "[27524 rows x 2 columns]\n",
      "Number of edges in a graph:  27524\n",
      "Number of nodes in a graph:  27525\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "list_nodes = []\n",
    "with open('user_connections_largest_all.pickle', 'rb') as f:\n",
    "    list_nodes = pickle.load(f)\n",
    "df = pd.DataFrame(list_nodes)\n",
    "print(df)\n",
    "square_edges = pd.DataFrame(\n",
    "    {\"source\": list(df['name']), \"target\": list(df['friend_id'])}\n",
    ")\n",
    "G = StellarGraph(edges=square_edges)\n",
    "print(\"Number of nodes in a graph: \", len(G.nodes(\n",
    "print(\"Number of edges in a graph: \", len(G.edges())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = BiasedRandomWalk(G)\n",
    "listP = ['0.25', '0.5', '1', '2', '4']\n",
    "listQ = ['0.25', '0.5', '1', '2', '4']\n",
    "\n",
    "walks = rw.run(\n",
    "    nodes=list(G.nodes()),  # root nodes\n",
    "    length=100,  # maximum length of a random walk\n",
    "    n=10,  # number of random walks per root node\n",
    "    p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "    q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    ")\n",
    "str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "model = Word2Vec(str_walks, size=128, window=5, min_count=0, sg=1, workers=2, iter=1)\n",
    "model.save(\"word2vec_all.emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve node embeddings and corresponding subjects\n",
    "node_ids = model.wv.index2word  # list of node IDs\n",
    "node_embeddings = (\n",
    "    model.wv.vectors\n",
    ")  # numpy.ndarray of size number of nodes times embeddings dimensionality\n",
    "node_targets = []\n",
    "with open('more_infomation_user_data_all.pickle', 'rb') as f:\n",
    "    list_data = pickle.load(f)\n",
    "node_targets = list(map(lambda x: list_data[int(x)]['sex'] == 2, list(G.nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE transformation on node embeddings\n",
    "tsne = TSNE(n_components=2)\n",
    "node_embeddings_2d = tsne.fit_transform(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12821145  0.02586343 -0.07407126 ... -0.43985105 -0.37039977\n",
      "   0.00741956]\n",
      " [ 0.3918243  -0.08428633 -0.18402256 ... -0.5646923  -0.2086265\n",
      "   0.31127685]\n",
      " [ 0.634222    0.40543392 -0.4549686  ... -0.00812502 -0.35599172\n",
      "   0.37701967]\n",
      " ...\n",
      " [-0.01429506  0.3625685  -0.3982914  ... -0.35324797 -0.23437437\n",
      "   0.1871579 ]\n",
      " [ 0.17943375  0.08861817 -0.14759657 ... -0.4017508  -0.30400375\n",
      "  -0.02730793]\n",
      " [ 0.39652437  0.45078734 -0.38598537 ... -0.3984166  -0.0514182\n",
      "  -0.16765761]]\n"
     ]
    }
   ],
   "source": [
    "# X will hold the input features\n",
    "X = node_embeddings\n",
    "print(X)\n",
    "# y holds the corresponding target values\n",
    "y = np.array(node_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, test_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array shapes:\n",
      " X_train = (16515, 128)\n",
      " y_train = (16515,)\n",
      " X_test = (11010, 128)\n",
      " y_test = (11010,)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Array shapes:\\n X_train = {}\\n y_train = {}\\n X_test = {}\\n y_test = {}\".format(\n",
    "        X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=2, cv=2, max_iter=300, multi_class='ovr',\n",
       "                     scoring='accuracy', verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(\n",
    "    Cs=2, cv=2, scoring=\"accuracy\", verbose=False, multi_class=\"ovr\", max_iter=300\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5143505903723887"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_node2vec_model_all.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
