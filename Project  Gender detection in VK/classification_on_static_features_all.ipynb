{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification based on static features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"more_infomation_user_data_all.pickle\"\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_cc_nodes_more_info_new = pd.DataFrame(data).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"user_data_all.pickle\"\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197940\n",
      "170415\n"
     ]
    }
   ],
   "source": [
    "list_index = list(df_cc_nodes_more_info_new.index)\n",
    "print(len(data.keys()))\n",
    "for item in list_index:\n",
    "    if item in data:\n",
    "        del data[item]\n",
    "print(len(data.keys()))\n",
    "df_found_users_id_to_info = pd.DataFrame(data).transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get male users ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "male_id = list(df_cc_nodes_more_info_new[df_cc_nodes_more_info_new['sex'] == 2]['id'])\n",
    "male_id += list(df_found_users_id_to_info[df_found_users_id_to_info['sex'] == 2]['id'])\n",
    "\n",
    "male_id = np.unique(male_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find male users between downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144506883     True\n",
      "295010307     True\n",
      "279117834     True\n",
      "5111819       True\n",
      "65548         True\n",
      "             ...  \n",
      "139952117    False\n",
      "142704631    False\n",
      "34340858     False\n",
      "154337275    False\n",
      "45481981     False\n",
      "Name: target, Length: 27525, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df_cc_nodes_more_info_new[\"target\"] = df_cc_nodes_more_info_new.apply(lambda x: x.id in male_id, axis=1)\n",
    "df_found_users_id_to_info[\"target\"] = df_found_users_id_to_info.apply(lambda x: x.id in male_id, axis=1)\n",
    "print(df_cc_nodes_more_info_new[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_NOT_KNOWN = -100\n",
    "\n",
    "for cname in df_cc_nodes_more_info_new.columns:\n",
    "    if cname not in df_found_users_id_to_info.columns and cname != \"target\":\n",
    "        df_found_users_id_to_info[cname] = IS_NOT_KNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_match = {\"FirstName\" : \"first_name\", \"LastName\": \"last_name\", \"Name\": \"domain\", \"ScreenName\": \"screen_name\",\n",
    "               \"Status\": \"status\", \"Country\": \"country_title\", \"City\": \"city_title\", \"Site\": \"site\",\n",
    "               'IsVerified': \"verified\", '_Sex': \"sex\", 'Birthday': \"bdate\",\n",
    "               'Universities': \"university_name\", 'LastSeen': \"last_seen_time\", 'Relatives':\"relatives\",\n",
    "               'GroupsCount': \"counters_groups\", 'PublicPagesCount': \"counters_subscriptions\",\n",
    "               'SubscribersCount': \"counters_followers\", 'PhotosCount':\"counters_photos\", 'VideosCount':\"counters_videos\",\n",
    "               'AudiosCount':\"counters_audios\", 'target':\"target\", \"id\":\"id\"}\n",
    "\n",
    "\n",
    "columns_to_drop = ['Sntag', 'WorkflowId', 'CrawlId', 'LoadDate', 'ID', 'Url', 'IsDeactivated', 'IsWallSetCommentEnabled', 'partialBirthDate',\n",
    "                            'IsWallSetPostEnabled', 'FriendsCount', 'NotesCount', 'IsWallGetPostEnabled',\n",
    "                            'IsPrivateMessageEnabled', 'UserPicURL', 'Groups', 'Schools', \"JSON_occupation\"]\n",
    "columns_to_drop_not = [\"Jobs\", \"Relation\", \"ExternalProfiles\"]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Everything:\n",
    "df_cc_nodes_more_info\n",
    "df_cc_nodes_more_info_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170415\n",
      "27525\n"
     ]
    }
   ],
   "source": [
    "print(len(df_found_users_id_to_info))\n",
    "print(len(df_cc_nodes_more_info_new))\n",
    "concated_df = pd.concat([df_found_users_id_to_info, df_cc_nodes_more_info_new], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_df.domain = concated_df.apply(lambda x: np.nan if x.domain != IS_NOT_KNOWN and str(x.domain).startswith('id') else x.domain, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>sex</th>\n",
       "      <th>university_name</th>\n",
       "      <th>target</th>\n",
       "      <th>can_access_closed</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>status_audio_url</th>\n",
       "      <th>status_audio_date</th>\n",
       "      <th>status_audio_main_artists</th>\n",
       "      <th>status_audio_short_videos_allowed</th>\n",
       "      <th>status_audio_stories_allowed</th>\n",
       "      <th>status_audio_stories_cover_allowed</th>\n",
       "      <th>status_audio_lyrics_id</th>\n",
       "      <th>status_audio_genre_id</th>\n",
       "      <th>status_audio_subtitle</th>\n",
       "      <th>maiden_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>42597</td>\n",
       "      <td>Alyona</td>\n",
       "      <td>Pustovalova</td>\n",
       "      <td>42597</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>Anastasia</td>\n",
       "      <td>Balashova</td>\n",
       "      <td>440</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>ГУУ</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19244</td>\n",
       "      <td>Ksenya</td>\n",
       "      <td>Akhumyan</td>\n",
       "      <td>19244</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>ВГИК</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20817</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>20817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20898</td>\n",
       "      <td>Nadezhda</td>\n",
       "      <td>Mikhalaki</td>\n",
       "      <td>20898</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139952117</td>\n",
       "      <td>Lena</td>\n",
       "      <td>Leonova</td>\n",
       "      <td>139952117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>id139952117</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142704631</td>\n",
       "      <td>Vika</td>\n",
       "      <td>Krot</td>\n",
       "      <td>142704631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>vikagrr</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34340858</td>\n",
       "      <td>Rimma</td>\n",
       "      <td>Oraztaeva</td>\n",
       "      <td>34340858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>id34340858</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154337275</td>\n",
       "      <td>Evgenia</td>\n",
       "      <td>Yurchenko</td>\n",
       "      <td>154337275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>ДВФУ</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>id154337275</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45481981</td>\n",
       "      <td>Elena</td>\n",
       "      <td>Yarenchuk</td>\n",
       "      <td>45481981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>e.yarenchuk</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197940 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          first_name    last_name         id country sex university_name  \\\n",
       "42597         Alyona  Pustovalova      42597  Russia   1             NaN   \n",
       "440        Anastasia    Balashova        440  Russia   1             ГУУ   \n",
       "19244         Ksenya     Akhumyan      19244  Russia   1            ВГИК   \n",
       "20817      Champagne      Charlie      20817     NaN   1             NaN   \n",
       "20898       Nadezhda    Mikhalaki      20898  Russia   1             NaN   \n",
       "...              ...          ...        ...     ...  ..             ...   \n",
       "139952117       Lena      Leonova  139952117     NaN   1                   \n",
       "142704631       Vika         Krot  142704631     NaN   1                   \n",
       "34340858       Rimma    Oraztaeva   34340858     NaN   1             NaN   \n",
       "154337275    Evgenia    Yurchenko  154337275     NaN   1            ДВФУ   \n",
       "45481981       Elena    Yarenchuk   45481981     NaN   1             NaN   \n",
       "\n",
       "           target can_access_closed is_closed  screen_name  ...  \\\n",
       "42597       False              -100      -100         -100  ...   \n",
       "440         False              -100      -100         -100  ...   \n",
       "19244       False              -100      -100         -100  ...   \n",
       "20817       False              -100      -100         -100  ...   \n",
       "20898       False              -100      -100         -100  ...   \n",
       "...           ...               ...       ...          ...  ...   \n",
       "139952117   False              True     False  id139952117  ...   \n",
       "142704631   False              True     False      vikagrr  ...   \n",
       "34340858    False             False      True   id34340858  ...   \n",
       "154337275   False              True     False  id154337275  ...   \n",
       "45481981    False             False      True  e.yarenchuk  ...   \n",
       "\n",
       "          status_audio_url status_audio_date status_audio_main_artists  \\\n",
       "42597                 -100              -100                      -100   \n",
       "440                   -100              -100                      -100   \n",
       "19244                 -100              -100                      -100   \n",
       "20817                 -100              -100                      -100   \n",
       "20898                 -100              -100                      -100   \n",
       "...                    ...               ...                       ...   \n",
       "139952117              NaN               NaN                       NaN   \n",
       "142704631              NaN               NaN                       NaN   \n",
       "34340858               NaN               NaN                       NaN   \n",
       "154337275              NaN               NaN                       NaN   \n",
       "45481981               NaN               NaN                       NaN   \n",
       "\n",
       "          status_audio_short_videos_allowed status_audio_stories_allowed  \\\n",
       "42597                                  -100                         -100   \n",
       "440                                    -100                         -100   \n",
       "19244                                  -100                         -100   \n",
       "20817                                  -100                         -100   \n",
       "20898                                  -100                         -100   \n",
       "...                                     ...                          ...   \n",
       "139952117                               NaN                          NaN   \n",
       "142704631                               NaN                          NaN   \n",
       "34340858                                NaN                          NaN   \n",
       "154337275                               NaN                          NaN   \n",
       "45481981                                NaN                          NaN   \n",
       "\n",
       "          status_audio_stories_cover_allowed status_audio_lyrics_id  \\\n",
       "42597                                   -100                   -100   \n",
       "440                                     -100                   -100   \n",
       "19244                                   -100                   -100   \n",
       "20817                                   -100                   -100   \n",
       "20898                                   -100                   -100   \n",
       "...                                      ...                    ...   \n",
       "139952117                                NaN                    NaN   \n",
       "142704631                                NaN                    NaN   \n",
       "34340858                                 NaN                    NaN   \n",
       "154337275                                NaN                    NaN   \n",
       "45481981                                 NaN                    NaN   \n",
       "\n",
       "          status_audio_genre_id status_audio_subtitle maiden_name  \n",
       "42597                      -100                  -100        -100  \n",
       "440                        -100                  -100        -100  \n",
       "19244                      -100                  -100        -100  \n",
       "20817                      -100                  -100        -100  \n",
       "20898                      -100                  -100        -100  \n",
       "...                         ...                   ...         ...  \n",
       "139952117                   NaN                   NaN              \n",
       "142704631                   NaN                   NaN              \n",
       "34340858                    NaN                   NaN              \n",
       "154337275                   NaN                   NaN              \n",
       "45481981                    NaN                   NaN              \n",
       "\n",
       "[197940 rows x 104 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_df[concated_df == IS_NOT_KNOWN] = np.nan\n",
    "concated_df.fillna(IS_NOT_KNOWN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_INT = -10\n",
    "concated= concated_df\n",
    "concated = concated.apply(pd.to_numeric, errors='coerce').fillna(STRING_INT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated.reset_index(inplace=True)\n",
    "concated = concated.drop_duplicates(subset=['id', 'has_photo', 'verified', 'counters_photos'], keep='last').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\"target\", \"sex\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "clf = tree.DecisionTreeClassifier(class_weight = \"balanced\")\n",
    "train_data = np.float32(np.array(concated.drop(drop_columns, axis=1)))\n",
    "train_data[np.logical_not(np.isfinite(train_data))] = IS_NOT_KNOWN\n",
    "clf = clf.fit(train_data, concated.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Droped columns: ['target', 'sex']\n"
     ]
    }
   ],
   "source": [
    "importance = sorted(list(zip(concated.drop(drop_columns, axis=1).columns, clf.feature_importances_)), key=lambda x: x[1])\n",
    "print(\"Droped columns:\", drop_columns)\n",
    "train_data = np.float32(np.array(concated.drop(drop_columns, axis=1).reset_index()))\n",
    "train_data[np.logical_not(np.isfinite(train_data))] = IS_NOT_KNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important columns: {'twitter', 'status_audio_subtitle', 'counters_user_photos', 'status_audio_short_videos_allowed', 'id', 'livejournal', 'status_audio_artist', 'status_audio_id', 'country', 'counters_audios', 'facebook', 'movies', 'occupation_id', 'personal_religion_id', 'military', 'skype', 'education_form', 'last_name', 'counters_clips', 'country_id', 'maiden_name', 'relation_partner_last_name', 'status_audio_title', 'games', 'books', 'city_id', 'relation_partner_id', 'status_audio_genre_id', 'domain', 'counters_albums', 'quotes', 'deactivated', 'status_audio_stories_allowed', 'relatives', 'personal_inspired_by', 'country_title', 'status_audio_is_explicit', 'status_audio_track_code', 'status_audio_main_artists', 'tv', 'counters_photos', 'personal_alcohol', 'occupation_name', 'counters_videos', 'counters_pages', 'personal_langs', 'has_photo', 'personal_smoking', 'trending', 'has_mobile', 'personal_people_main', 'counters_posts', 'status_audio_duration', 'music', 'personal_life_main', 'relation_partner_first_name', 'activities', 'facebook_name', 'faculty', 'about', 'first_name', 'counters_clips_followers', 'nickname', 'city_title', 'status_audio_url', 'interests', 'status', 'status_audio_stories_cover_allowed', 'counters_groups', 'bdate', 'occupation_type', 'personal_religion', 'mobile_phone', 'personal_political', 'status_audio_date', 'status_audio_owner_id', 'relation', 'counters_gifts', 'education_status', 'last_seen_platform', 'university_name', 'home_town', 'last_seen_time', 'counters_articles', 'screen_name', 'schools', 'can_access_closed', 'home_phone', 'status_audio_is_focus_track', 'faculty_name', 'university', 'career', 'is_closed', 'personal', 'site', 'verified', 'counters_followers', 'counters_subscriptions', 'instagram', 'graduation', 'universities', 'status_audio_lyrics_id'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Important columns:\", set(concated_df.columns) - set(drop_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "42597        False\n",
      "440          False\n",
      "19244        False\n",
      "20817        False\n",
      "20898        False\n",
      "             ...  \n",
      "139952117    False\n",
      "142704631    False\n",
      "34340858     False\n",
      "154337275    False\n",
      "45481981     False\n",
      "Name: target, Length: 197940, dtype: bool\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "target = concated.target\n",
    "print(target)\n",
    "print(target.loc[22383])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = np.unique(target.index, return_index = True)\n",
    "unique_indexes = unique[1]\n",
    "unique_indexing = unique[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.values[unique_indexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[unique_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data_all.pickle', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "with open('train_index_all.pickle', 'wb') as f:\n",
    "    pickle.dump(unique_indexing, f)\n",
    "with open('train_target_all.pickle', 'wb') as f:\n",
    "    pickle.dump(target, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target, test_size = 0.2, \n",
    "                                                    stratify = target, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/.local/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:1544: RuntimeWarning: overflow encountered in multiply\n",
      "  sqr = np.multiply(arr, arr, out=arr)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_consider = [(\"LogReg\", \n",
    "                       LogisticRegression(class_weight = \"balanced\", max_iter = 1000), \n",
    "                       {\"solver\" : (\"lbfgs\",),\n",
    "                        'C':[1, 5, 10]}),\n",
    "                      (\"RandomForestClassifier\", \n",
    "                       RandomForestClassifier(class_weight = \"balanced\"), \n",
    "                       {\"n_estimators\":[10, 50, 100]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.72      0.67     21792\n",
      "        True       0.58      0.47      0.52     17796\n",
      "\n",
      "    accuracy                           0.61     39588\n",
      "   macro avg       0.60      0.59      0.59     39588\n",
      "weighted avg       0.60      0.61      0.60     39588\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.62      0.61     21792\n",
      "        True       0.53      0.52      0.53     17796\n",
      "\n",
      "    accuracy                           0.57     39588\n",
      "   macro avg       0.57      0.57      0.57     39588\n",
      "weighted avg       0.57      0.57      0.57     39588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = dict()\n",
    "clf_grid = dict()\n",
    "\n",
    "for (model_name, model, model_params) in models_to_consider:\n",
    "    print(model_name)\n",
    "    clf_grid[model_name] = GridSearchCV(model, model_params, cv = 5, scoring = 'roc_auc')\n",
    "    clf_grid[model_name].fit(X_train, y_train)\n",
    "    y_pred = clf_grid[model_name].predict(X_test)\n",
    "    res[model_name] = clf_grid[model_name].score(X_test, y_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results obtaibed by classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogReg': 0.6507494452856802, 'RandomForestClassifier': 0.5977735637601416}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_static_model_all.pickle', 'wb') as f:\n",
    "    pickle.dump({\"classifier\":clf_grid[\"LogReg\"], \"scaler\": scaler}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
